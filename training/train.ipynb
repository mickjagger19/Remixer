{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:17:24.260127Z",
     "start_time": "2023-12-05T14:17:17.294097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmickjagger19\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Disabling SSL verification.  Connections to this server are not verified and may be insecure!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "from train import *\n",
    "\n",
    "# os.environ['WANDB_NOTEBOOK_NAME'] = str(pathlib.Path().absolute())\n",
    "\n",
    "init(False)\n",
    "\n",
    "# write_basic_config(mixed_precision=\"no\", save_location='~/.cache/huggingface/accelerate/default_config.yaml')\n",
    "print(accelerate.accelerator.AcceleratorState._shared_state)\n",
    "\n",
    "\n",
    "def launch(x, args):\n",
    "    os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "    os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "    notebook_launcher(x, args=args, num_processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train VAE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f472bcc58ff7bea3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading \n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Disabling SSL verification.  Connections to this server are not verified and may be insecure!\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111357258632779, max=1.0)â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0696680ff38048e1a5faebb46a107b4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/root/autodl-tmp/remixer/training/wandb/run-20231205_221727-9k177rml</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/mickjagger19/VAE/runs/9k177rml' target=\"_blank\">silvery-grass-43</a></strong> to <a href='https://wandb.ai/mickjagger19/VAE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/mickjagger19/VAE' target=\"_blank\">https://wandb.ai/mickjagger19/VAE</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/mickjagger19/VAE/runs/9k177rml' target=\"_blank\">https://wandb.ai/mickjagger19/VAE/runs/9k177rml</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "An issue was found when launching the training: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/utils/launch.py\", line 562, in __call__\n    self.launcher(*args)\n  File \"/root/autodl-tmp/remixer/training/train.py\", line 98, in train_vae\n    for step, batch in enumerate(dataloader):\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/data_loader.py\", line 448, in __iter__\n    current_batch = next(dataloader_iter)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n    data = self._next_data()\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataset.py\", line 302, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"/root/autodl-tmp/remixer/core/data/util.py\", line 72, in __getitem__\n    datum = self.codec.encode(datum)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 67, in <lambda>\n    self.encode = lambda x: chain_functions(encodes, x, config)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 13, in chain_functions\n    return functools.reduce(lambda acc, func: func(acc, config), functions, X)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 13, in <lambda>\n    return functools.reduce(lambda acc, func: func(acc, config), functions, X)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 22, in audio_to_mel_spec\n    S = librosa.feature.melspectrogram(y=y, sr=config.sr, n_fft=config.n_fft, n_mels=config.n_mels, dtype=np.float32)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/librosa/feature/spectral.py\", line 2130, in melspectrogram\n    S, n_fft = _spectrogram(\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/librosa/core/spectrum.py\", line 2817, in _spectrogram\n    raise ParameterError(\nlibrosa.util.exceptions.ParameterError: Input signal must be provided to compute a spectrogram\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mProcessRaisedException\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/launchers.py:186\u001B[0m, in \u001B[0;36mnotebook_launcher\u001B[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m     \u001B[43mstart_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlauncher\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_processes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfork\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ProcessRaisedException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:202\u001B[0m, in \u001B[0;36mstart_processes\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001B[39;00m\n\u001B[0;32m--> 202\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:163\u001B[0m, in \u001B[0;36mProcessContext.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    162\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m original_trace\n\u001B[0;32m--> 163\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ProcessRaisedException(msg, error_index, failed_process\u001B[38;5;241m.\u001B[39mpid)\n",
      "\u001B[0;31mProcessRaisedException\u001B[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/utils/launch.py\", line 562, in __call__\n    self.launcher(*args)\n  File \"/root/autodl-tmp/remixer/training/train.py\", line 98, in train_vae\n    for step, batch in enumerate(dataloader):\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/data_loader.py\", line 448, in __iter__\n    current_batch = next(dataloader_iter)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n    data = self._next_data()\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataset.py\", line 302, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"/root/autodl-tmp/remixer/core/data/util.py\", line 72, in __getitem__\n    datum = self.codec.encode(datum)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 67, in <lambda>\n    self.encode = lambda x: chain_functions(encodes, x, config)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 13, in chain_functions\n    return functools.reduce(lambda acc, func: func(acc, config), functions, X)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 13, in <lambda>\n    return functools.reduce(lambda acc, func: func(acc, config), functions, X)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 22, in audio_to_mel_spec\n    S = librosa.feature.melspectrogram(y=y, sr=config.sr, n_fft=config.n_fft, n_mels=config.n_mels, dtype=np.float32)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/librosa/feature/spectral.py\", line 2130, in melspectrogram\n    S, n_fft = _spectrogram(\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/librosa/core/spectrum.py\", line 2817, in _spectrogram\n    raise ParameterError(\nlibrosa.util.exceptions.ParameterError: Input signal must be provided to compute a spectrogram\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 26\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# vae_path = ''\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# from dataclasses import asdict\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# print(asdict(vae_config))\u001B[39;00m\n\u001B[1;32m     25\u001B[0m accelerate_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 26\u001B[0m \u001B[43mlaunch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_vae\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 16\u001B[0m, in \u001B[0;36mlaunch\u001B[0;34m(x, args)\u001B[0m\n\u001B[1;32m     14\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNCCL_P2P_DISABLE\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     15\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNCCL_IB_DISABLE\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 16\u001B[0m \u001B[43mnotebook_launcher\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_processes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/launchers.py:196\u001B[0m, in \u001B[0;36mnotebook_launcher\u001B[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001B[0m\n\u001B[1;32m    189\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    190\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA has been initialized before the `notebook_launcher` could create a forked subprocess. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    191\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis likely stems from an outside import causing issues once the `notebook_launcher()` is called. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    192\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease review your imports and test them when running the `notebook_launcher()` to identify \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    193\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhich one is problematic and causing CUDA to be initialized.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    194\u001B[0m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    195\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 196\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn issue was found when launching the training: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;66;03m# No need for a distributed launch otherwise as it's either CPU, GPU or MPS.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_mps_available():\n",
      "\u001B[0;31mRuntimeError\u001B[0m: An issue was found when launching the training: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 74, in _wrap\n    fn(i, *args)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/utils/launch.py\", line 562, in __call__\n    self.launcher(*args)\n  File \"/root/autodl-tmp/remixer/training/train.py\", line 98, in train_vae\n    for step, batch in enumerate(dataloader):\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/accelerate/data_loader.py\", line 448, in __iter__\n    current_batch = next(dataloader_iter)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n    data = self._next_data()\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/torch/utils/data/dataset.py\", line 302, in __getitem__\n    return self.datasets[dataset_idx][sample_idx]\n  File \"/root/autodl-tmp/remixer/core/data/util.py\", line 72, in __getitem__\n    datum = self.codec.encode(datum)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 67, in <lambda>\n    self.encode = lambda x: chain_functions(encodes, x, config)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 13, in chain_functions\n    return functools.reduce(lambda acc, func: func(acc, config), functions, X)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 13, in <lambda>\n    return functools.reduce(lambda acc, func: func(acc, config), functions, X)\n  File \"/root/autodl-tmp/remixer/core/data/codes.py\", line 22, in audio_to_mel_spec\n    S = librosa.feature.melspectrogram(y=y, sr=config.sr, n_fft=config.n_fft, n_mels=config.n_mels, dtype=np.float32)\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/librosa/feature/spectral.py\", line 2130, in melspectrogram\n    S, n_fft = _spectrogram(\n  File \"/root/miniconda3/envs/remixer/lib/python3.9/site-packages/librosa/core/spectrum.py\", line 2817, in _spectrogram\n    raise ParameterError(\nlibrosa.util.exceptions.ParameterError: Input signal must be provided to compute a spectrogram\n"
     ]
    }
   ],
   "source": [
    "vae_config = TrainingConfig()\n",
    "\n",
    "# vae_config.train_batch_size = 11\n",
    "vae_config.train_batch_size = 41\n",
    "vae_config.num_epochs = 10\n",
    "vae_config.vae_learning_rate = 1e-5\n",
    "vae_config.save_model_epochs = 2\n",
    "vae_config.save_image_epochs = 2\n",
    "\n",
    "trainer = Trainer(\n",
    "    vae_path='',\n",
    "    generator_path='',\n",
    "    config=vae_config,\n",
    "    dataset_paths=['gtzan', 'fma']\n",
    ")\n",
    "\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "vae_path = ''\n",
    "# vae_path = ''\n",
    "# from dataclasses import asdict\n",
    "# \n",
    "# print(asdict(vae_config))\n",
    "\n",
    "accelerate_path = ''\n",
    "launch(\n",
    "    trainer.train_vae, (True, None))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:17:35.310018Z",
     "start_time": "2023-12-05T14:17:24.214910Z"
    }
   },
   "id": "a4f455aab3807fa2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Train Diffusion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7922fe12fc983a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diffusion_config = TrainingConfig()\n",
    "diffusion_config.train_batch_size = 3\n",
    "diffusion_config.num_epochs = 4\n",
    "diffusion_config.latent_channels = 4\n",
    "diffusion_config.save_model_epochs = 2\n",
    "diffusion_config.save_image_epochs = 2\n",
    "\n",
    "trainer = Trainer(\n",
    "    vae_path='',\n",
    "    generator_path='',\n",
    "    config=diffusion_config,\n",
    "    dataset_paths=['gtzan', 'fma']\n",
    ")\n",
    "\n",
    "launch(trainer.train_diffusion, ())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T14:17:35.309345Z"
    }
   },
   "id": "7d6e9be7dd697f98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35aa16e3aa4ed015"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = TrainingConfig()\n",
    "from test_model import *\n",
    "\n",
    "vae_path = '/root/autodl-tmp/remixer/training/artifacts/atomic-armadillo-16/AutoencoderKL/model_epoch_7.pth'\n",
    "generator_path = '/root/autodl-tmp/remixer/training/artifacts/celestial-firebrand-7/VQGenerator/model_epoch_1.pth'\n",
    "scheduler_path = '/root/autodl-tmp/remixer/training/artifacts/celestial-firebrand-7/scheduler_config.json'\n",
    "\n",
    "# vae_path = '/root/autodl-tmp/remixer/training/artifacts/kind-spaceship-380/AutoencoderKL/kind-spaceship-380_models_epoch_9.pth'\n",
    "config.num_inference_steps = 999\n",
    "datas = [generate_from_genre(config, genre=None,\n",
    "                             vae_path=vae_path,\n",
    "                             generator_path=generator_path,\n",
    "                             scheduler_path=scheduler_path)\n",
    "         for _ in range(3)]\n",
    "\n",
    "make_grid([img for output, img in datas])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T14:17:35.312399Z"
    }
   },
   "id": "1357553b6109b04a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-05T14:17:35.312984Z",
     "start_time": "2023-12-05T14:17:35.312586Z"
    }
   },
   "id": "6f32acfe09be87ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-05T14:17:35.312730Z"
    }
   },
   "id": "cad1d7b88c027c96"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
